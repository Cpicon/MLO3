{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit and HuggingFace Stater Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============= PART 1 =============\n",
    "The first part of this excercise is to figure out how to instantiate a Reddit API object using the [PRAW library](https://praw.readthedocs.io/en/stable/). This is a Python library that gives easy to understand interfaces to interact with the Reddit API.\n",
    "\n",
    "Your first task is to look through the [documentation here](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) and figure out how to instanstiate a Reddit instance. (hint: you only need to use `client_id`, `client_secret`, and `user_agent`)\n",
    "\n",
    "Make sure everyone in the group does this part! Follow the guide below on how to get your `client_id` and `client_secret`.\n",
    "\n",
    "### Steps for part 1:\n",
    "1. Pull the `FourthBrain/ML03` repo locally so you can start development.\n",
    "2. Open `reddit_and_huggingface.ipynb` and install the necessary packages for this lesson by running:\n",
    "\n",
    "    ```\n",
    "    cd code_student/Week_2\n",
    "    conda activate {your_virtual_environment_name}\n",
    "    pip install transformers praw torch torchvision torchaudio\n",
    "    ```\n",
    "\n",
    "3. Get your `client_id` and `client_secret` from Reddit by doing:\n",
    "\n",
    "* Make a Reddit account\n",
    "* Follow the steps in this screenshot which are the first steps from this [guide](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c).\n",
    "\n",
    "![instructions to set up reddit api](../../images/reddit_get_access.JPG)\n",
    "\n",
    "* Create a `secrets.py` file and include the following:\n",
    "\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"\"\n",
    "    REDDIT_API_USER_AGENT = {can_be_any_string...for ex: \"marksbot\"}\n",
    "    ```\n",
    "\n",
    "* Put `secrets.py` in `Week_2` so you can easily import it\n",
    "\n",
    "4. Read the [documentation here](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) and try to figure out how to instanstiate a Reddit instance object. \n",
    "5. Lastly, once you have your Reddit instance object, figure out how to make a `subreddit` object for your favorite subreddit. (hint: look for `subreddit` in the documentation)\n",
    "6. If time permits, continue to browse the documentation to prep for the next part of this excercise which will be to get submissions from the subreddit of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import secrets\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=secrets.REDDIT_API_CLIENT_ID,\n",
    "    client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent=secrets.REDDIT_API_USER_AGENT\n",
    ")\n",
    "subreddit = reddit.subreddit(\"wallstreetbets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============= PART 2 =============\n",
    "\n",
    "This next part you are going to figure out how to parse comments by using your `subreddit` instance object.\n",
    "\n",
    "### Todos for part 2:\n",
    "1. How do I find the top 10 posts of all time from your favorite subreddit(s)? (hint: look at [\"Obtain Submission Instances from a Subreddit\"](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html))\n",
    "2. How do I parse comments from the post? (hint: look at [\"Obtain Submission Instances from a Subreddit\"](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html))\n",
    "3. And finally, how do I parse replies from that comment? (hint: look at [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html))\n",
    "\n",
    "Put your scraped data into a list so you can use it in the next part. A good structure would be a list of lists where the inner list is one comment and its replies. (hint: you might need a TRIPLE nested for loop). This could take a minute or two once running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praw.models import MoreComments\n",
    "\n",
    "# Get top 100 posts of all time and iterate over them putting all comments and replies into a flat list\n",
    "top_comments_and_replies = []\n",
    "\n",
    "for submission in subreddit.top(limit=10):\n",
    "    for top_level_comment in submission.comments:\n",
    "        convo = []\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "                    continue\n",
    "        convo.append(top_level_comment.body)\n",
    "        for reply in top_level_comment.replies:\n",
    "            if isinstance(reply, MoreComments):\n",
    "                continue\n",
    "            convo.append(reply.body)\n",
    "        top_comments_and_replies.append(convo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============= PART 3 =============\n",
    "\n",
    "The last part is to somehow use the data you have scraped from Reddit to run a HuggingFace model inference. \n",
    "\n",
    "### Todos for part 3:\n",
    "\n",
    "1. Look at each of these HuggingFace models and choose one to implement:\n",
    "    * [News Classification](https://huggingface.co/mrm8488/bert-mini-finetuned-age_news-classification) [HARD]\n",
    "    * [Sentiment Analysis](https://huggingface.co/docs/transformers/quicktour) [EASY]\n",
    "    * [Text Generation](https://huggingface.co/tasks/text-generation) [EASY]\n",
    "2. Once you have chosen a model, go ahead and implement it!\n",
    "3. If time permits, try another!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markr\\anaconda3\\envs\\week-2-student\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the blanks for News Classification to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 327kB/s]\n",
      "Downloading: 100%|██████████| 523M/523M [00:20<00:00, 26.1MB/s] \n",
      "Downloading: 100%|██████████| 0.99M/0.99M [00:00<00:00, 4.25MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 2.28MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 4.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "news_tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-mini-finetuned-age_news-classification\") \n",
    "news_model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/bert-mini-finetuned-age_news-classification\")\n",
    "\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "text_generation_model = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for News Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "NEWS_CLASSES = [\"world\", \"sports\", \"business\", \"sci/tech\"]\n",
    "\n",
    "# Take the output from our news classifier and map it to a class\n",
    "def map_news_output_to_class(inference_output: torch.Tensor) -> str:\n",
    "    softmax_values = []\n",
    "    for output in inference_output:\n",
    "        softmax_values.append(output.item())\n",
    "    max_value = max(softmax_values)\n",
    "    max_index = softmax_values.index(max_value)\n",
    "    return NEWS_CLASSES[max_index]\n",
    "\n",
    "# Run the news classifier model on the input\n",
    "def run_subject_analysis(query: str) -> str:\n",
    "    inputs = news_tokenizer(query, return_tensors=\"pt\")\n",
    "    labels = torch.tensor([1]).unsqueeze(0) # Batch size of 1\n",
    "    outputs = news_model(**inputs, labels=labels) # Unpack key-value pairs into keyword args in function call\n",
    "    news_subject = map_news_output_to_class(outputs.logits[0]) # Taking softmax tensor from inference\n",
    "    return news_subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_conversation(conversations):\n",
    "    text = \"\"\n",
    "    conversation = random.choice(conversations)\n",
    "    for comment in conversation:\n",
    "        text = text + \" \" + comment\n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_random_comment(conversations):\n",
    "    convo = random.choice(conversations)\n",
    "    comment = random.choice(convo)\n",
    "    \n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment test: reddit recap says i was one of the first to upvote this === [{'label': 'POSITIVE', 'score': 0.958552360534668}]\n"
     ]
    }
   ],
   "source": [
    "# Run sentiment analysis\n",
    "sentiment_query_sentence = get_random_comment(top_comments_and_replies)\n",
    "sentiment = sentiment_model(sentiment_query_sentence)\n",
    "print(f\"Sentiment test: {sentiment_query_sentence} === {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generation:  If DFV doesn't win man of the year 2021, I no longer believe in the award. === [{'generated_text': \" If DFV doesn't win man of the year 2021, I no longer believe in the award. I'm a fan of the current and former winners of the year awards. Even if I don't win it, I still hope to play in the\"}]\n"
     ]
    }
   ],
   "source": [
    "# Run text summarization\n",
    "text_generation_query = get_random_conversation(top_comments_and_replies)\n",
    "text_generation = text_generation_model(text_generation_query)\n",
    "print(f\"Text generation: {text_generation_query} === {text_generation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Category:  If gme hits $1000 EOW I’m naming my son DFV. You heard it here. \n",
      "\n",
      "200 shares @$291 === business\n"
     ]
    }
   ],
   "source": [
    "# Run news categorization analysis\n",
    "category_query = get_random_conversation(top_comments_and_replies)\n",
    "category = run_subject_analysis(category_query)\n",
    "print(f\"News Category: {category_query} === {category}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70e5a9886b02a227d3c83e17263e3a28d12f842d6950be488144931078452c0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('jims4thbrain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
